{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "df73ec14",
      "metadata": {
        "id": "df73ec14"
      },
      "source": [
        "# DEEP LEARNING _ FINAL PROJECT (PART 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c04e57b8",
      "metadata": {
        "id": "c04e57b8"
      },
      "source": [
        "> ## Members: \n",
        "> <p style=\"text-align: left;\"><font color = blue > Amanuel Abrdo Tereda</p>\n",
        "> <p style=\"text-align: left;\"><font color = blue > Stefalo Acha</p>\n",
        "\n",
        "***\n",
        "> *Date: May 02, 2023*\n",
        "> ### <p style=\"text-align: right;\">Instructor: <font color = blue > Dr. Letu Qingge</p>\n",
        "***\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ac89364",
      "metadata": {
        "id": "3ac89364"
      },
      "source": [
        "## Image classification with different Neural Netowrk setups\n",
        "\n",
        "> **1. 100 ReLU hidden units, 5 Sigmoid output units, MeanSquaredError loss**\n",
        "\n",
        "> **2.\t100 Tanh hidden units, 5 Sigmoid output units, MeanSquaredError loss**\n",
        "\n",
        "> **3.\t100 Sigmoid hidden units, 5 Sigmoid output units, MeanSquaredError loss**\n",
        "\n",
        "> **4.\t100 Sigmoid hidden units, 5 Linear output units, Softmax loss**\n",
        "\n",
        "> **5.\t100 Tanh hidden units, 5 Linear output units, Softmax loss**\n",
        "\n",
        "        - Without an optimizer and an initialization\n",
        "    \n",
        "        - With an optimizer of momentum = 0.9, weight decay = 0.02, and 'glorot' initialization.\n",
        "\n",
        "        - With an optimizer of momentum = 0.9, weight decay = 0.02, and 'random' initialization.\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a561c46a",
      "metadata": {
        "id": "a561c46a"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Amumu-ze1ast/Deep_Learning_Final_try.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae3d4093",
      "metadata": {
        "id": "ae3d4093"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/Deep_Learning_Final_try/lincoln.zip\", 'r') as zip_ref:\n",
        "    zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19d6f9ab",
      "metadata": {
        "id": "19d6f9ab"
      },
      "outputs": [],
      "source": [
        "import lincoln\n",
        "from lincoln.layers import Dense\n",
        "from lincoln.losses import SoftmaxCrossEntropy, MeanSquaredError\n",
        "from lincoln.optimizers import Optimizer, SGD, SGDMomentum\n",
        "from lincoln.activations import Sigmoid, Tanh, Linear, ReLU\n",
        "from lincoln.network import NeuralNetwork\n",
        "from lincoln.train import Trainer\n",
        "from lincoln.utils import mnist\n",
        "from lincoln.utils.np_utils import softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d44f3036",
      "metadata": {
        "id": "d44f3036"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import PIL.Image as Image\n",
        "import os\n",
        "import matplotlib.pylab as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9de6b616",
      "metadata": {
        "id": "9de6b616"
      },
      "outputs": [],
      "source": [
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url,  cache_dir='.', untar=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "136019a9",
      "metadata": {
        "id": "136019a9"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "list_images = list(data_dir.glob('*/*.jpg'))\n",
        "image_count = len(list_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "214c4ab5",
      "metadata": {
        "id": "214c4ab5"
      },
      "outputs": [],
      "source": [
        "#Make up python dictionary\n",
        "\n",
        "flowers_images_dict = {\n",
        "    'roses': list(data_dir.glob('roses/*')),\n",
        "    'daisy': list(data_dir.glob('daisy/*')),\n",
        "    'dandelion': list(data_dir.glob('dandelion/*')),\n",
        "    'sunflowers': list(data_dir.glob('sunflowers/*')),\n",
        "    'tulips': list(data_dir.glob('tulips/*')),\n",
        "}\n",
        "\n",
        "#Creating a label directory\n",
        "\n",
        "flowers_labels_dict = {\n",
        "    'roses': 0,\n",
        "    'daisy': 1,\n",
        "    'dandelion': 2,\n",
        "    'sunflowers': 3,\n",
        "    'tulips': 4,\n",
        "}\n",
        "\n",
        "class_names = list(flowers_labels_dict.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f035ec67",
      "metadata": {
        "id": "f035ec67"
      },
      "outputs": [],
      "source": [
        "# Resize all images using for loop\n",
        "\n",
        "IMAGE_SHAPE = (224,224)\n",
        "#IMAGE_SHAPE = (28,28)\n",
        "\n",
        "x, y = [], []\n",
        "\n",
        "for flower_name, images in flowers_images_dict.items():\n",
        "    for image in images:\n",
        "        img = cv2.imread(str(image))\n",
        "        \n",
        "        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        resized_img = cv2.resize(img_gray,(IMAGE_SHAPE)) #IMAGE_SHAPE = (224,224)\n",
        "        \n",
        "        #resized_img = cv2.resize(img,(IMAGE_SHAPE)) #IMAGE_SHAPE = (224,224)\n",
        "        \n",
        "        x.append(resized_img)\n",
        "        y.append(flowers_labels_dict[flower_name])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2017ed55",
      "metadata": {
        "id": "2017ed55"
      },
      "outputs": [],
      "source": [
        "x[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8a42a7e",
      "metadata": {
        "id": "d8a42a7e"
      },
      "outputs": [],
      "source": [
        "x = np.array(x)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5f8aa5d",
      "metadata": {
        "id": "d5f8aa5d"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1/3, random_state=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d06d945",
      "metadata": {
        "id": "0d06d945"
      },
      "outputs": [],
      "source": [
        "x_train, x_test = x_train - np.mean(x_train), x_test - np.mean(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6598fe2",
      "metadata": {
        "id": "d6598fe2"
      },
      "outputs": [],
      "source": [
        "np.min(x_train), np.max(x_train), np.min(x_test), np.max(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cfd5624",
      "metadata": {
        "id": "1cfd5624"
      },
      "outputs": [],
      "source": [
        "x_train, x_test = x_train / np.std(x_train), x_test / np.std(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6133868e",
      "metadata": {
        "scrolled": true,
        "id": "6133868e"
      },
      "outputs": [],
      "source": [
        "np.min(x_train), np.max(x_train), np.min(x_test), np.max(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0d69592",
      "metadata": {
        "scrolled": false,
        "id": "a0d69592"
      },
      "outputs": [],
      "source": [
        "#verify\n",
        "print(\"shape of input  - training set =\", x_train.shape)\n",
        "print(\"shape of output - training set =\", y_train.shape)\n",
        "print(\"shape of input  - testing set  =\", x_test.shape)\n",
        "print(\"shape of output - testing set  =\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dee520ce",
      "metadata": {
        "id": "dee520ce"
      },
      "outputs": [],
      "source": [
        "x_train.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea41feab",
      "metadata": {
        "id": "ea41feab"
      },
      "outputs": [],
      "source": [
        "x_train = x_train.reshape(len(x_train),(x_train.shape[1])*(x_train.shape[1]))\n",
        "x_test  = x_test.reshape(len(x_test),(x_test.shape[1])*(x_test.shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fbb8c75",
      "metadata": {
        "scrolled": true,
        "id": "7fbb8c75"
      },
      "outputs": [],
      "source": [
        "#verify\n",
        "print(\"shape of input  - training set =\", x_train.shape)\n",
        "print(\"shape of output - training set =\", y_train.shape)\n",
        "print(\"shape of input  - testing set  =\", x_test.shape)\n",
        "print(\"shape of output - testing set  =\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8f2793a",
      "metadata": {
        "id": "b8f2793a"
      },
      "outputs": [],
      "source": [
        "num_labels = len(y_train)\n",
        "train_labels = np.zeros((num_labels, 5))\n",
        "for i in range(num_labels):\n",
        "    train_labels[i][y_train[i]] = 1\n",
        "\n",
        "num_labels = len(y_test)\n",
        "test_labels = np.zeros((num_labels, 5))\n",
        "for i in range(num_labels):\n",
        "    test_labels[i][y_test[i]] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e24fb31",
      "metadata": {
        "id": "1e24fb31"
      },
      "outputs": [],
      "source": [
        "#verify\n",
        "print(\"shape of input  - training set    =\", x_train.shape)\n",
        "print(\"shape of output - training lables =\", train_labels.shape)\n",
        "print(\"shape of input  - testing set     =\", x_test.shape)\n",
        "print(\"shape of output - test labels     =\", test_labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1596db8c",
      "metadata": {
        "id": "1596db8c"
      },
      "outputs": [],
      "source": [
        "def calc_accuracy_model(model, test_set):\n",
        "    return print(f'''The model validation accuracy is: \n",
        "    {np.equal(np.argmax(model.forward(test_set, inference=True), axis=1), y_test).sum() * 100.0 / test_set.shape[0]:.2f}%''')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d90ad98e",
      "metadata": {
        "id": "d90ad98e"
      },
      "source": [
        "### a) 100 ReLU hidden units, 5 Sigmoid output units, MeanSquaredError loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8bf4b9d",
      "metadata": {
        "id": "f8bf4b9d"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork(\n",
        "    layers=[Dense(neurons=100, \n",
        "                  activation=ReLU()),\n",
        "            Dense(neurons=5, \n",
        "                  activation=Sigmoid())],\n",
        "            loss = MeanSquaredError(normalize=False), \n",
        "seed=20190119)\n",
        "\n",
        "print('100 ReLU hidden units, 5 Sigmoid output units, MeanSquaredError loss')\n",
        "print('_________________________________/\\____________________________________')\n",
        "\n",
        "trainer = Trainer(model, SGD(0.1))\n",
        "trainer.fit(x_train, train_labels, x_test, test_labels,\n",
        "            epochs = 70,\n",
        "            eval_every = 10,\n",
        "            seed=20190119,\n",
        "            batch_size=70);\n",
        "print()\n",
        "print('_________________________________\\/____________________________________')\n",
        "calc_accuracy_model(model, x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0157fc8",
      "metadata": {
        "id": "f0157fc8"
      },
      "source": [
        "### b) 100 Tanh hidden units, 5 Sigmoid output units, MeanSquaredError loss "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ff9faa6",
      "metadata": {
        "id": "5ff9faa6"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork(\n",
        "    layers=[Dense(neurons=100, \n",
        "                  activation=Tanh()),\n",
        "            Dense(neurons=5, \n",
        "                  activation=Sigmoid())],\n",
        "            loss = MeanSquaredError(normalize=False), \n",
        "seed=20190119)\n",
        "\n",
        "print('100 Tanh hidden units, 5 Sigmoid output units, MeanSquaredError loss')\n",
        "print('_________________________________/\\____________________________________')\n",
        "\n",
        "trainer = Trainer(model, SGD(0.1))\n",
        "trainer.fit(x_train, train_labels, x_test, test_labels,\n",
        "            epochs = 70,\n",
        "            eval_every = 10,\n",
        "            seed=20190119,\n",
        "            batch_size=70);\n",
        "print()\n",
        "print('_________________________________\\/____________________________________')\n",
        "calc_accuracy_model(model, x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3250cb7f",
      "metadata": {
        "id": "3250cb7f"
      },
      "source": [
        "### c) 100 Sigmoid hidden units, 5 Sigmoid output units, MeanSquaredError loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a6d0496",
      "metadata": {
        "scrolled": true,
        "id": "7a6d0496"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork(\n",
        "    layers=[Dense(neurons=100, \n",
        "                  activation=Sigmoid()),\n",
        "            Dense(neurons=5, \n",
        "                  activation=Sigmoid())],\n",
        "            loss = MeanSquaredError(normalize=False), \n",
        "seed=20190119)\n",
        "\n",
        "print('100 Sigmoid hidden units, 5 Sigmoid output units, MeanSquaredError loss')\n",
        "print('_________________________________/\\____________________________________')\n",
        "\n",
        "trainer = Trainer(model, SGD(0.1))\n",
        "trainer.fit(x_train, train_labels, x_test, test_labels,\n",
        "            epochs = 70,\n",
        "            eval_every = 10,\n",
        "            seed=20190119,\n",
        "            batch_size=70);\n",
        "print()\n",
        "print('_________________________________\\/____________________________________')\n",
        "calc_accuracy_model(model, x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8b7e4a1",
      "metadata": {
        "id": "d8b7e4a1"
      },
      "source": [
        "### d) 100 Sigmoid hidden units, 5 Linear output units, Softmax loss "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "747b9588",
      "metadata": {
        "scrolled": true,
        "id": "747b9588"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork(\n",
        "    layers=[Dense(neurons=100, \n",
        "                  activation=Sigmoid()),\n",
        "            Dense(neurons=5, \n",
        "                  activation=Linear())],\n",
        "            loss = SoftmaxCrossEntropy(), \n",
        "seed=20190119)\n",
        "\n",
        "print('100 Sigmoid hidden units, 5 Linear output units, Softmax loss')\n",
        "print('_________________________________/\\____________________________________')\n",
        "\n",
        "trainer = Trainer(model, SGD(0.1))\n",
        "trainer.fit(x_train, train_labels, x_test, test_labels,\n",
        "            epochs = 10,\n",
        "            eval_every = 1,\n",
        "            seed=20190119,\n",
        "            batch_size=70);\n",
        "print()\n",
        "print('_________________________________\\/____________________________________')\n",
        "calc_accuracy_model(model, x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "780fc26e",
      "metadata": {
        "id": "780fc26e"
      },
      "source": [
        "### e) 100 Tanh hidden units, 5 Linear output units, Softmax loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f74fbb1e",
      "metadata": {
        "id": "f74fbb1e"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork(\n",
        "    layers=[Dense(neurons=100, \n",
        "                  activation=Tanh()),\n",
        "            Dense(neurons=5, \n",
        "                  activation=Linear())],\n",
        "            loss = SoftmaxCrossEntropy(), \n",
        "seed=20190119)\n",
        "\n",
        "print('100 Tanh hidden units, 5 Linear output units, Softmax loss')\n",
        "print('_________________________________/\\____________________________________')\n",
        "\n",
        "trainer = Trainer(model, SGD(0.1))\n",
        "trainer.fit(x_train, train_labels, x_test, test_labels,\n",
        "            epochs = 70,\n",
        "            eval_every = 10,\n",
        "            seed=20190119,\n",
        "            batch_size=70);\n",
        "print()\n",
        "print('_________________________________\\/____________________________________')\n",
        "calc_accuracy_model(model, x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bce067c",
      "metadata": {
        "id": "4bce067c"
      },
      "source": [
        "## Comparing the weight initialization algorithms for the best model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f32c3ee",
      "metadata": {
        "id": "7f32c3ee"
      },
      "source": [
        "### a) Random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2a9c864",
      "metadata": {
        "id": "a2a9c864"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork(\n",
        "    layers=[Dense(neurons=100, \n",
        "                  activation=Tanh(),\n",
        "                  weight_init=\"random\"),\n",
        "            Dense(neurons=5, \n",
        "                  activation=Linear(),\n",
        "                  weight_init=\"random\")],\n",
        "            loss = SoftmaxCrossEntropy(), \n",
        "seed=20190119)\n",
        "\n",
        "optimizer = SGDMomentum(0.25, \n",
        "                        momentum=0.9, \n",
        "                        final_lr = 0.02, \n",
        "                        decay_type='exponential')\n",
        "\n",
        "print('100 Tanh hidden units, 5 Linear output units, Softmax loss')\n",
        "print(\"With an optimizer of momentum = 0.9, weight decay = 0.02, and 'random' initialization\")\n",
        "print('_________________________________/\\____________________________________')\n",
        "\n",
        "trainer = Trainer(model, optimizer)\n",
        "trainer.fit(x_train, train_labels, x_test, test_labels,\n",
        "            epochs = 70,\n",
        "            eval_every = 10,\n",
        "            seed=20190119,\n",
        "            batch_size=70);\n",
        "print()\n",
        "calc_accuracy_model(model, x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db41ce91",
      "metadata": {
        "id": "db41ce91"
      },
      "source": [
        "### b) Glorot "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "917ea1f0",
      "metadata": {
        "id": "917ea1f0"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork(\n",
        "    layers=[Dense(neurons=100, \n",
        "                  activation=Tanh(),\n",
        "                  weight_init=\"glorot\"),\n",
        "            Dense(neurons=5, \n",
        "                  activation=Linear(),\n",
        "                  weight_init=\"glorot\")],\n",
        "            loss = SoftmaxCrossEntropy(), \n",
        "seed=20190119)\n",
        "\n",
        "optimizer = SGDMomentum(0.25, \n",
        "                        momentum=0.9, \n",
        "                        final_lr = 0.02, \n",
        "                        decay_type='exponential')\n",
        "\n",
        "print('100 Tanh hidden units, 5 Linear output units, Softmax loss')\n",
        "print(\"With an optimizer of momentum = 0.9, weight decay = 0.02, and 'glorot' initialization\")\n",
        "print('_________________________________/\\____________________________________')\n",
        "\n",
        "trainer = Trainer(model, optimizer)\n",
        "trainer.fit(x_train, train_labels, x_test, test_labels,\n",
        "            epochs = 70,\n",
        "            eval_every = 10,\n",
        "            seed=20190119,\n",
        "            batch_size=70);\n",
        "print()\n",
        "print('_________________________________\\/____________________________________')\n",
        "calc_accuracy_model(model, x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b5f56ef",
      "metadata": {
        "id": "0b5f56ef"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}